{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4ae26b-3f4a-48aa-b870-8e1bd70778a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./lib_helper_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351fbf44-459e-49b0-8746-af8fbbab2fc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example Merge CSV\n",
    "#\n",
    "# source_place_canonical_id,target_place_canonical_id,merge_reason\n",
    "# abc123,def456,\"Same parish; punctuation and token order variation\"\n",
    "# ghi789,def456,\"Same town, country variant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b27f0e1f-8b79-46cf-a4e9-d33e66a7cd9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_place_canonical_merges_from_csv(\n",
    "    csv_path: str,\n",
    "    dry_run: bool = True\n",
    "):\n",
    "    df = (\n",
    "        spark.read\n",
    "             .option(\"header\", True)\n",
    "             .option(\"inferSchema\", False)\n",
    "             .csv(csv_path)\n",
    "    )\n",
    "\n",
    "    required_cols = {\n",
    "        \"source_place_canonical_id\",\n",
    "        \"target_place_canonical_id\",\n",
    "        \"merge_reason\"\n",
    "    }\n",
    "\n",
    "    if not required_cols.issubset(set(df.columns)):\n",
    "        raise ValueError(f\"CSV must contain columns: {required_cols}\")\n",
    "\n",
    "    rows = df.collect()\n",
    "\n",
    "    print(f\"Running {len(rows)} canonical place merges\")\n",
    "    print(f\"Dry run: {dry_run}\")\n",
    "\n",
    "    for row in rows:\n",
    "        merge_place_canonicals(\n",
    "            source_canonical_id=row[\"source_place_canonical_id\"],\n",
    "            target_canonical_id=row[\"target_place_canonical_id\"],\n",
    "            merge_reason=row[\"merge_reason\"],\n",
    "            merged_by=\"ed.ball\",\n",
    "            dry_run=dry_run\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c355d76-5a2d-40dd-968b-b562c455ec3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uploaded_path = \"/Volumes/workspace/genealogy/file_uploads/place_canonical_merges.csv\" \n",
    "run_place_canonical_merges_from_csv(uploaded_path, False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exec_merge_place_batchrunner",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
