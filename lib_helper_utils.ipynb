{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "458416d5-f1b6-4523-a4d5-a6bf130a1614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# --------------------------------------------\n",
    "# Library: Helper utilities\n",
    "# Author: Ed Ball (via ChatGPT)\n",
    "# Purpose:\n",
    "#   - Provide reusable helper functions for common warehouse actions\n",
    "# --------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0712e590-ecaa-4953-a3bf-c8bbee0b15a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8770519f-6ce0-41f8-ab6c-30ebdaaffc78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def merge_place_canonicals(\n",
    "    source_canonical_id: str,\n",
    "    target_canonical_id: str,\n",
    "    merge_reason: str,\n",
    "    merged_by: str = None,\n",
    "    dry_run: bool = False\n",
    "):\n",
    "    if source_canonical_id == target_canonical_id:\n",
    "        raise ValueError(\"Source and target canonical IDs must be different.\")\n",
    "\n",
    "    if not merge_reason or merge_reason.strip() == \"\":\n",
    "        raise ValueError(\"merge_reason is required and must be meaningful.\")\n",
    "\n",
    "    merged_by = merged_by or \"unknown\"\n",
    "\n",
    "    canonical = spark.table(\"genealogy.silver_place_canonical\")\n",
    "\n",
    "    source = canonical.filter(col(\"canonical_place_id\") == source_canonical_id).collect()\n",
    "    target = canonical.filter(col(\"canonical_place_id\") == target_canonical_id).collect()\n",
    "\n",
    "    if not source:\n",
    "        raise ValueError(f\"Source canonical {source_canonical_id} does not exist.\")\n",
    "\n",
    "    if not target:\n",
    "        raise ValueError(f\"Target canonical {target_canonical_id} does not exist.\")\n",
    "\n",
    "    if not source[0][\"is_active\"]:\n",
    "        raise ValueError(f\"Source canonical {source_canonical_id} is already inactive.\")\n",
    "\n",
    "    if not target[0][\"is_active\"]:\n",
    "        raise ValueError(f\"Target canonical {target_canonical_id} is not active.\")\n",
    "\n",
    "    print(f\"Merging canonical place {source_canonical_id} → {target_canonical_id}\")\n",
    "    print(f\"Dry run: {dry_run}\")\n",
    "\n",
    "    if dry_run:\n",
    "        # Preview impact\n",
    "        variant_count = spark.table(\"genealogy.silver_place_variant\") \\\n",
    "            .filter(f\"canonical_place_id = '{source_canonical_id}'\").count()\n",
    "\n",
    "        print(f\"Would reassign {variant_count} variants\")\n",
    "        source_name = source[0][\"preferred_name\"]\n",
    "        target_name = target[0][\"preferred_name\"]\n",
    "        print(f\"Would merge source canonical record {source_name} into target canonical record {target_name}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    # --- Step 1: retire source canonical\n",
    "    spark.sql(f\"\"\"\n",
    "        UPDATE genealogy.silver_place_canonical\n",
    "        SET\n",
    "          is_active = false,\n",
    "          merged_into_canonical_id = '{target_canonical_id}',\n",
    "          merge_reason = '{merge_reason}',\n",
    "          merge_timestamp = current_timestamp()\n",
    "        WHERE canonical_place_id = '{source_canonical_id}'\n",
    "    \"\"\")\n",
    "\n",
    "    # --- Step 2: repoint variants\n",
    "    spark.sql(f\"\"\"\n",
    "        UPDATE genealogy.silver_place_variant\n",
    "        SET canonical_place_id = '{target_canonical_id}'\n",
    "        WHERE canonical_place_id = '{source_canonical_id}'\n",
    "    \"\"\")\n",
    "\n",
    "    # --- Step 3: write merge log\n",
    "    spark.sql(f\"\"\"\n",
    "        INSERT INTO genealogy.silver_place_merge_log\n",
    "        VALUES (\n",
    "          '{source_canonical_id}',\n",
    "          '{target_canonical_id}',\n",
    "          '{merge_reason}',\n",
    "          '{merged_by}',\n",
    "          current_timestamp()\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"✅ Merged canonical {source_canonical_id} → {target_canonical_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lib_helper_utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
