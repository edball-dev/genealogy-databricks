{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d5b5cb-cd7a-4d36-815b-6a245bec961e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./lib_gedcom_text_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b27f3524-5b32-4aa7-a892-2462ab264447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T, Window\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Load your GEDCOM-lines table\n",
    "# ----------------------------\n",
    "ged_raw = spark.table(\"genealogy.bronze_gedcom_with_record\") \\\n",
    "    .select(\"record_xref\", \"line_no\", \"level\", \"tag\", \"value\", \"source_file\")\n",
    "\n",
    "# Drop header lines\n",
    "#ged = ged_raw.where(F.col(\"record_xref\").isNotNull()) Commented out as this is also removing the root source records\n",
    "\n",
    "# Optional: improve parallelism if you have lots of records\n",
    "ged = ged_raw.repartition(\"record_xref\")\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Configure your extraction logic\n",
    "# ----------------------------\n",
    "EVENT_WHITELIST = {\n",
    "    \"BIRT\", \"BAPM\", \"CHR\", \"DEAT\", \"BURI\", \"CREM\", \"PROB\", # Vital events\n",
    "    \"CENS\", \"EMIG\", \"IMMI\", \"NATU\", # Migration/census events \n",
    "    \"MARR\", \"DIV\", \"_SEPR\", # Family formation/breakdown events\n",
    "    \"RESI\", \"EDUC\", \"OCCU\", \"GRAD\", \"RETI\", # Event-like\n",
    "    \"EVEN\", \"FACT\", # generic\n",
    "    \"_MILT\", \"_FUN\", \"_EMPLOY\", \"_MDCL\", # custom events\n",
    "    \"NAME\", \"SEX\" # attributes\n",
    "    }  \n",
    "# Anything under these subtree roots is ignored for event attrs (prevents picking up SOUR.DATE etc.)\n",
    "IGNORE_SUBTREE_ROOTS = {\"SOUR\", \"OBJE\", \"REPO\"}\n",
    "\n",
    "# Tags we want to pivot into columns (you can add more)\n",
    "ATTR_TAGS = {\"DATE\", \"PLAC\", \"NOTE\", \"TYPE\", \"CONC\", \"CONT\"}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Enrich each line with parent + owning event + blocked flags (stack walk per record_xref)\n",
    "# ----------------------------\n",
    "enriched_schema = T.StructType([\n",
    "    T.StructField(\"record_xref\", T.StringType(), True),\n",
    "    T.StructField(\"line_no\", T.IntegerType(), False),\n",
    "    T.StructField(\"level\", T.IntegerType(), False),\n",
    "    T.StructField(\"tag\", T.StringType(), True),\n",
    "    T.StructField(\"value\", T.StringType(), True),\n",
    "\n",
    "    T.StructField(\"parent_line_no\", T.IntegerType(), True),\n",
    "\n",
    "    # owning event for this line (nearest ancestor in EVENT_WHITELIST)\n",
    "    T.StructField(\"event_line_no\", T.IntegerType(), True),\n",
    "    T.StructField(\"event_tag\", T.StringType(), True),\n",
    "\n",
    "    # whether this line is inside an ignored subtree (e.g., under SOUR)\n",
    "    T.StructField(\"blocked\", T.BooleanType(), False),\n",
    "\n",
    "    # for NOTE/CONC/CONT assembly: which NOTE line this piece belongs to\n",
    "    T.StructField(\"note_root_line_no\", T.IntegerType(), True),\n",
    "\n",
    "    # for tracking sources and citations\n",
    "    T.StructField(\"source_root_line_no\", T.IntegerType(), True),\n",
    "    T.StructField(\"citation_root_line_no\", T.IntegerType(), True),\n",
    "\n",
    "    T.StructField(\"source_file\", T.StringType(), False),\n",
    "])\n",
    "\n",
    "def enrich_record(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    pdf = pdf.sort_values(\"line_no\", kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # stack items: (level, line_no, tag)\n",
    "    stack = []\n",
    "\n",
    "    out_parent = []\n",
    "    out_event_line = []\n",
    "    out_event_tag = []\n",
    "    out_blocked = []\n",
    "    out_note_root = []\n",
    "    out_source_root = []\n",
    "    out_citation_root = []\n",
    "\n",
    "    for _, row in pdf.iterrows():\n",
    "        level = int(row[\"level\"])\n",
    "        tag = row[\"tag\"]\n",
    "\n",
    "        # Pop until top has level < current level (so top becomes parent)\n",
    "        while stack and stack[-1][0] >= level:\n",
    "            stack.pop()\n",
    "\n",
    "        parent_line_no = stack[-1][1] if stack else None\n",
    "        out_parent.append(parent_line_no)\n",
    "\n",
    "        # blocked if any ancestor tag is an ignored subtree root\n",
    "        blocked = any(a_tag in IGNORE_SUBTREE_ROOTS for (_, _, a_tag) in stack)\n",
    "        out_blocked.append(bool(blocked))\n",
    "\n",
    "        # determine owning event (including self if current tag is an event)\n",
    "        event_ln = None\n",
    "        event_tg = None\n",
    "\n",
    "        # If current line is itself an event, it owns itself\n",
    "        if tag in EVENT_WHITELIST:\n",
    "            event_ln = int(row[\"line_no\"])\n",
    "            event_tg = tag\n",
    "        else:\n",
    "            for (lvl, ln, tg) in reversed(stack):\n",
    "                if tg in EVENT_WHITELIST:\n",
    "                    event_ln = ln\n",
    "                    event_tg = tg\n",
    "                    break\n",
    "\n",
    "        out_event_line.append(event_ln)\n",
    "        out_event_tag.append(event_tg)\n",
    "\n",
    "        # NOTE root tracking for NOTE/CONC/CONT pieces\n",
    "        note_root = None\n",
    "        if tag == \"NOTE\":\n",
    "            note_root = int(row[\"line_no\"])\n",
    "        elif tag in (\"CONC\", \"CONT\"):\n",
    "            # nearest NOTE ancestor\n",
    "            for (lvl, ln, tg) in reversed(stack):\n",
    "                if tg == \"NOTE\":\n",
    "                    note_root = ln\n",
    "                    break\n",
    "        out_note_root.append(note_root)\n",
    "\n",
    "        source_root = None\n",
    "        citation_root = None\n",
    "\n",
    "        # Walk ancestors to find nearest SOURCE root\n",
    "        for (lvl, ln, tg) in reversed(stack):\n",
    "            if tg == \"SOUR\":\n",
    "                # level 0 SOUR = source definition\n",
    "                if lvl == 0:\n",
    "                    source_root = ln\n",
    "                else:\n",
    "                    # level >=2 SOUR = citation\n",
    "                    citation_root = ln\n",
    "                break\n",
    "\n",
    "        out_source_root.append(source_root)\n",
    "        out_citation_root.append(citation_root)\n",
    "\n",
    "        # push current node\n",
    "        stack.append((level, int(row[\"line_no\"]), tag))\n",
    "\n",
    "    pdf[\"parent_line_no\"] = out_parent\n",
    "    pdf[\"event_line_no\"] = out_event_line\n",
    "    pdf[\"event_tag\"] = out_event_tag\n",
    "    pdf[\"blocked\"] = out_blocked\n",
    "    pdf[\"note_root_line_no\"] = out_note_root\n",
    "    pdf[\"source_root_line_no\"] = out_source_root\n",
    "    pdf[\"citation_root_line_no\"] = out_citation_root\n",
    "\n",
    "    return pdf[[\n",
    "        \"record_xref\", \"line_no\", \"level\", \"tag\", \"value\",\n",
    "        \"parent_line_no\", \"event_line_no\", \"event_tag\",\n",
    "        \"blocked\", \"note_root_line_no\", \"source_root_line_no\", \"citation_root_line_no\",\n",
    "        \"source_file\"\n",
    "    ]]\n",
    "\n",
    "enriched = ged.groupBy(\"record_xref\").applyInPandas(enrich_record, schema=enriched_schema)\n",
    "\n",
    "enriched_resolved = (\n",
    "    resolve_bronze_gedcom_text(enriched)\n",
    "    .join(\n",
    "        enriched.select(\"record_xref\", \"line_no\", \"level\", \"event_line_no\", \"event_tag\", \"blocked\", \"note_root_line_no\", \"source_root_line_no\", \"citation_root_line_no\"),\n",
    "        on=[\"line_no\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "(enriched_resolved.write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\", \"true\")\n",
    "  .saveAsTable(\"genealogy.bronze_gedcom_enriched\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_enrich_gedcom",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
